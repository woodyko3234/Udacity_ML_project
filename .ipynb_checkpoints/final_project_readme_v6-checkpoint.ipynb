{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Identify Fraud from Enron Email - Intro to ML Project\n",
    "##Woody Yao\n",
    "\n",
    "##Introduction \n",
    "In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud. In the resulting Federal investigation, a significant amount of typically confidential information entered into the public record, including tens of thousands of emails and detailed financial data for top executives. The scandal has brought great impacts on accounting worldwide, which I majored in university, making me more interested in digging into the dataset. In this project, I would play a detective, and put my new skills into it by building a person of interest identifier based on financial and email data made public as a result of the Enron scandal. \n",
    "Please note that the python version I dealt with was 3.5, which was different from the version the starter codes applied in many ways. As a result, I would modify the starter codes to keep them out of malfunctioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the dataset and get understanding about the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type:  <class 'dict'>\n",
      "Data frame and data points in total:  [('KEAN STEVEN J', {'loan_advances': 'NaN', 'from_this_person_to_poi': 387, 'expenses': 41953, 'deferral_payments': 'NaN', 'total_payments': 1747522, 'long_term_incentive': 300000, 'from_poi_to_this_person': 140, 'salary': 404338, 'restricted_stock': 4131594, 'to_messages': 12754, 'exercised_stock_options': 2022048, 'restricted_stock_deferred': 'NaN', 'poi': False, 'shared_receipt_with_poi': 3639, 'other': 1231, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'total_stock_value': 6153642, 'email_address': 'steven.kean@enron.com', 'bonus': 1000000, 'from_messages': 6759})] 146\n",
      "Total features number:  21\n",
      "defaultdict(<class 'int'>, {'loan_advances': 142, 'from_this_person_to_poi': 80, 'expenses': 51, 'deferral_payments': 107, 'total_payments': 21, 'long_term_incentive': 80, 'from_poi_to_this_person': 72, 'salary': 51, 'restricted_stock': 36, 'exercised_stock_options': 44, 'to_messages': 60, 'bonus': 64, 'restricted_stock_deferred': 128, 'poi': 128, 'shared_receipt_with_poi': 60, 'other': 53, 'deferred_income': 97, 'total_stock_value': 20, 'email_address': 35, 'director_fees': 129, 'from_messages': 60})\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"rb\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "print (\"Data type: \", type(data_dict))\n",
    "print (\"Data frame and data points in total: \", list(data_dict.items())[0:1], len(data_dict.items()))\n",
    "print (\"Total features number: \", len(list(data_dict.items())[0][1]))\n",
    "\n",
    "def counting_machine(dictionary):\n",
    "    '''Put the original data_dict into this function\n",
    "        it would count how many nan and false values for each feature.'''\n",
    "    counter_dict = defaultdict(int)\n",
    "    for key, value_dict in dictionary.items():\n",
    "        for feature_key, feature_value in value_dict.items():\n",
    "            if feature_value == 'NaN' or feature_value == False:\n",
    "                counter_dict[feature_key] +=1\n",
    "    return counter_dict\n",
    "\n",
    "print(counting_machine(data_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data Structure\n",
    "After loading the dataset and printing out the first data point, we can see the data structure is a dictionary with 146 data point in total. The dictionary key was the person's name, and the value was another dictionary with 21 key-value pairs in total, which contained the names of all the features and their values for that person. The features in the data fell into three major types, namely financial features, email features and POI labels. \n",
    "See the first data point with dict.items method for example:\n",
    "\n",
    "[('PRENTICE JAMES', {'to_messages': 'NaN', 'director_fees': 'NaN', 'restricted_stock': 208809, 'bonus': 'NaN', 'deferred_income': 'NaN', 'email_address': 'james.prentice@enron.com', 'long_term_incentive': 'NaN', 'other': 'NaN', 'loan_advances': 'NaN', 'poi': False, 'salary': 'NaN', 'restricted_stock_deferred': 'NaN', 'deferral_payments': 564348, 'from_this_person_to_poi': 'NaN', 'total_stock_value': 1095040, 'from_poi_to_this_person': 'NaN', 'exercised_stock_options': 886231, 'from_messages': 'NaN', 'total_payments': 564348, 'shared_receipt_with_poi': 'NaN', 'expenses': 'NaN'})]\n",
    "\n",
    "###financial features: \n",
    "['salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees'] (all units are in US dollars)\n",
    "\n",
    "###email features: \n",
    "['to_messages', 'email_address', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi'] (units are generally number of emails messages; notable exception is ‘email_address’, which is a text string)\n",
    "\n",
    "###POI label: \n",
    "[‘poi’] (boolean, represented as integer)\n",
    "\n",
    "The interesting and hard part of the dataset was that the distribution of the non-POI's to POI's was very skewed, given that from the 146 there were only 18 people or data points labeled as POI's. I was interested in labeling every person in the dataset into either a POI or a non-POI (POI stands for Person Of Interest).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Features without value\n",
    "By digging the data structure more deeply, I found that not only POI distribution was very skewed, but there were a lot of none values expressed by string 'NaN'. Find the dictionary addressing how many NaN or false in each feature below:\n",
    "{'other': 53, 'deferred_income': 97, 'bonus': 64, 'restricted_stock': 36, 'deferral_payments': 107, 'director_fees': 129, 'email_address': 35, 'to_messages': 60, 'restricted_stock_deferred': 128, 'from_messages': 60, 'salary': 51, 'long_term_incentive': 80, 'total_payments': 21, 'poi': 128, 'from_this_person_to_poi': 80, 'shared_receipt_with_poi': 60, 'total_stock_value': 20, 'exercised_stock_options': 44, 'expenses': 51, 'loan_advances': 142, 'from_poi_to_this_person': 72}\n",
    "\n",
    "From the dictionary I found that even the salary, total payments, and messages sent and received got many none values, which might make the POI prediction more difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LOCKHART EUGENE E', 20), ('THE TRAVEL AGENCY IN THE PARK', 18), ('GRAMM WENDY L', 18), ('WROBEL BRUCE', 18), ('WHALEY DAVID A', 18), ('CLINE KENNETH W', 17), ('WODRASKA JOHN', 17), ('SAVAGE FRANK', 17), ('GILLIS JOHN', 17), ('SCRIMSHAW MATTHEW', 17), ('WAKEHAM JOHN', 17), ('CHRISTODOULOU DIOMEDES', 16), ('PEREIRA PAULO V. FERRAZ', 16), ('CHAN RONNIE', 16), ('BLAKE JR. NORMAN P', 16), ('WINOKUR JR. HERBERT S', 16), ('FUGH JOHN L', 16), ('GATHMANN WILLIAM D', 16), ('MENDELSOHN JOHN', 16), ('LOWRY CHARLES P', 16), ('URQUHART JOHN A', 16), ('YEAP SOON', 16), ('MEYER JEROME J', 16), ('DUNCAN JOHN H', 15), ('BADUM JAMES P', 15), ('GRAY RODNEY', 15), ('WALTERS GARETH W', 15), ('LEMAISTRE CHARLES', 15), ('NOLES JAMES L', 15), ('BELFER ROBERT', 14), ('PRENTICE JAMES', 14), ('JAEDICKE ROBERT', 13), ('HIRKO JOSEPH', 13), ('BERBERIAN DAVID', 13), ('BAZELIDES PHILIP J', 13), ('CUMBERLAND MICHAEL S', 12), ('LEWIS RICHARD', 12), ('BROWN MICHAEL', 12), ('PIRO JIM', 12), ('SULLIVAN-SHAKLOVITZ COLLEEN', 12), ('YEAGER F SCOTT', 12), ('HAYSLETT RODERICK J', 12), ('KISHKILL JOSEPH G', 12), ('STABLER FRANK', 12), ('MORDAUNT KRISTINA M', 12), ('POWERS WILLIAM', 12), ('GOLD JOSEPH', 11), ('MCCARTY DANNY J', 11), ('WHITE JR THOMAS E', 11), ('FOWLER PEGGY', 11), ('MCDONALD REBECCA', 11), ('HUGHES JAMES A', 11), ('KOPPER MICHAEL J', 11), ('WESTFAHL RICHARD K', 11), ('MORAN MICHAEL P', 11), ('OVERDYKE JR JERE C', 11), ('CORDES WILLIAM R', 11), ('PAI LOU L', 11), ('SHERRICK JEFFREY B', 11), ('HAUG DAVID L', 10), ('BUTTS ROBERT H', 10), ('FOY JOE', 10), ('DIMICHELE RICHARD G', 10), ('HAYES ROBERT E', 10), ('ELLIOTT STEVEN', 10), ('ECHOLS JOHN B', 10), ('GAHN ROBERT S', 10), ('UMANOFF ADAM S', 10), ('FASTOW ANDREW S', 10), ('DODSON KEITH', 9), ('BAY FRANKLIN R', 9), ('HORTON STANLEY C', 9), ('GIBBS DANA R', 9), ('HERMANN ROBERT J', 9), ('BAXTER JOHN C', 9), ('MEYER ROCKFORD G', 9), ('LINDHOLM TOD A', 9), ('HUMPHREY GENE E', 8), ('REYNOLDS LAWRENCE', 8), ('BHATNAGAR SANJAY', 8), ('REDMOND BRIAN L', 8), ('PICKERING MARK R', 7), ('BECK SALLY W', 7), ('METTS MARK', 7), ('SUNDE MARTIN', 7), ('TAYLOR MITCHELL S', 7), ('DETMERING TIMOTHY J', 7), ('LEFF DANIEL P', 7), ('IZZO LAWRENCE L', 6), ('TOTAL', 6), ('CARTER REBECCA C', 6), ('HICKERSON GARY J', 6), ('KITCHEN LOUISE', 6), ('MARTIN AMANDA K', 6), ('JACKSON CHARLENE R', 6), ('SHERRIFF JOHN R', 6), ('SHAPIRO RICHARD S', 6), ('KEAN STEVEN J', 5), ('WHALLEY LAWRENCE G', 5), ('GARLAND C KEVIN', 5), ('CAUSEY RICHARD A', 5), ('MCCLELLAN GEORGE', 5), ('WALLS JR ROBERT H', 5), ('SKILLING JEFFREY K', 5), ('CALGER CHRISTOPHER F', 5), ('SHELBY REX', 5), ('LAVORATO JOHN J', 5), ('COLWELL WESLEY', 5), ('DONAHUE JR JEFFREY M', 5), ('DURAN WILLIAM D', 5), ('BANNANTINE JAMES M', 5), ('SHANKMAN JEFFREY A', 5), ('MURRAY JULIA H', 5), ('MCCONNELL MICHAEL S', 5), ('MCMAHON JEFFREY', 5), ('COX DAVID', 5), ('BLACHMAN JEREMY M', 5), ('THORN TERENCE H', 5), ('BOWEN JR RAYMOND M', 5), ('DEFFNER JOSEPH M', 5), ('TILNEY ELIZABETH A', 5), ('GLISAN JR BEN F', 5), ('KOENIG MARK E', 5), ('DIETRICH JANET R', 5), ('BERGSIEKER RICHARD P', 5), ('BIBI PHILIPPE A', 5), ('FITZGERALD JAY L', 5), ('DELAINEY DAVID W', 5), ('FALLON JAMES B', 5), ('BUCHANAN HAROLD G', 5), ('KAMINSKI WINCENTY J', 5), ('RIEKER PAULA H', 4), ('RICE KENNETH D', 4), ('WASAFF GEORGE', 4), ('MULLER MARK S', 4), ('SHARP VICTORIA T', 4), ('HANNON KEVIN P', 4), ('BELDEN TIMOTHY N', 4), ('OLSON CINDY K', 4), ('BUY RICHARD B', 4), ('PIPER GREGORY F', 3), ('DERRICK JR. JAMES V', 3), ('HAEDICKE MARK E', 2), ('ALLEN PHILLIP K', 2), ('LAY KENNETH L', 2), ('FREVERT MARK A', 2)]\n"
     ]
    }
   ],
   "source": [
    "def ppl_counting(dictionary, value_appointed):\n",
    "    '''Put the original data_dict into this function and appoint what you want to count \n",
    "        ('NaN' or whatever you like)\n",
    "        it would count how many appointed values for each data point (employee).'''\n",
    "    counter_dict = defaultdict(int)\n",
    "    for key, value_dict in dictionary.items():\n",
    "        counter = 0\n",
    "        for value in value_dict.values():\n",
    "            if value == value_appointed:\n",
    "                counter += 1\n",
    "            else: continue\n",
    "        # The codes below is set for checking how poi and NaN value counts distribute\n",
    "        #if value_dict['poi'] == 0:\n",
    "        #    counter_dict[key] = counter\n",
    "        #else:\n",
    "        #    counter_dict[key] = -counter\n",
    "        counter_dict[key] = counter\n",
    "    return counter_dict\n",
    "\n",
    "NaN_count = ppl_counting(data_dict, 'NaN')\n",
    "print(sorted(NaN_count.items(), key = lambda counting: counting[1],\n",
    "                      reverse = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###None values counting for each person\n",
    "After knowing that there were a lot of none values in each feature, I created another dictionary to count the amount of missed values for each person. Here's the persons and their missed values in total (only including data points with count higher than 15):\n",
    "\n",
    "[('LOCKHART EUGENE E', 20), ('WHALEY DAVID A', 18), ('WROBEL BRUCE', 18), ('GRAMM WENDY L', 18), ('THE TRAVEL AGENCY IN THE PARK', 18), ('CLINE KENNETH W', 17), ('SAVAGE FRANK', 17), ('WAKEHAM JOHN', 17), ('WODRASKA JOHN', 17), ('GILLIS JOHN', 17), ('SCRIMSHAW MATTHEW', 17), ('CHAN RONNIE', 16), ('YEAP SOON', 16), ('CHRISTODOULOU DIOMEDES', 16), ('WINOKUR JR. HERBERT S', 16), ('MENDELSOHN JOHN', 16), ('BLAKE JR. NORMAN P', 16), ('URQUHART JOHN A', 16), ('PEREIRA PAULO V. FERRAZ', 16), ('LOWRY CHARLES P', 16), ('MEYER JEROME J', 16), ('GATHMANN WILLIAM D', 16), ('FUGH JOHN L', 16)]\n",
    "\n",
    "According to the fact I found out earlier, the total of key-value pairs in each datum is 21, and POI identity must be identified with boolean (True or False). As the person \"LOCKHART EUGENE E\" have 20 NaN values, I would say this datum was unable to help us predict or figure out who might be the POI because there were no effective features. Additionally, although the persons with NaN value count higher than 13 were all non-POI, we might not be able to assure and predict that every person with high NaN value count were all non-POI, and lacking of information might make the prediction easy to be biased.\n",
    "\n",
    "Before transforming the none values into numbers to easily analyze and run machine learning algorithms, I also check whether there were any zeros in the original dataset and I noticed that some data points had zeros besides the boolean value (False, non-POI). I would like to take this into consideration and turn the NaN values into -10. as a penalty value when doing the data transformation. Note that most value of feature \"deferred_income\" were negative, so I set the penalty to be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data pre-process and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature_names(dict):\n",
    "    \"Define a function to extract all features in the dict of dict and easier to plot\"\n",
    "    dict_values = list(dict.values())[0]\n",
    "    dict_values_features = list(dict_values.keys())\n",
    "    dict_values_features.remove('poi')\n",
    "    dict_values_features.remove('email_address')\n",
    "    dict_values_features = sorted(dict_values_features)\n",
    "    #print(dict_values_features)\n",
    "    return dict_values_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'bonus', 'deferral_payments', 'deferred_income', 'director_fees', 'exercised_stock_options', 'expenses', 'from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi', 'loan_advances', 'long_term_incentive', 'other', 'restricted_stock', 'restricted_stock_deferred', 'salary', 'shared_receipt_with_poi', 'to_messages', 'total_payments', 'total_stock_value']\n"
     ]
    }
   ],
   "source": [
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "#preprocess on the NaN value in the dictionary!!!\n",
    "def remove_nan(dict, penalty, remove_outlier = False):\n",
    "    '''looking through the dataset and \n",
    "    turn NaN into -1\n",
    "    also turn all integers into floats\n",
    "    and remove email_address'''\n",
    "    for point, sub_dict in dict.items():\n",
    "        for key, value in sub_dict.items():\n",
    "            if key == 'email_address': continue\n",
    "            if value == 'NaN' or np.isnan(value):\n",
    "                if key == 'deferred_income':\n",
    "                    sub_dict[key] = - float(penalty)\n",
    "                else:\n",
    "                    sub_dict[key] = float(penalty)\n",
    "            else:\n",
    "                sub_dict[key] = float( value )\n",
    "    if remove_outlier:\n",
    "        dict.pop('THE TRAVEL AGENCY IN THE PARK', 0)\n",
    "        dict.pop('TOTAL', 0)\n",
    "        dict.pop('LOCKHART EUGENE E', 0)\n",
    "    return dict\n",
    "my_dataset = remove_nan(my_dataset, -10, remove_outlier = True)\n",
    "\n",
    "def reset_feature_list(my_dataset):\n",
    "    ### features_list is a list of strings, each of which is a feature name.\n",
    "    ### The first feature must be \"poi\".\n",
    "    features_list = ['poi']\n",
    "    features_list.extend(extract_feature_names(my_dataset))\n",
    "    return features_list\n",
    "    #Total 20 features including poi as the first feature\n",
    "\n",
    "features_list = reset_feature_list(my_dataset)\n",
    "#print(list(my_dataset.items())[1])\n",
    "print(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the \"NaN\" values, I created a features list to store all features in the dataset. This would help a lot when I needed to put features into any algorithms to analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Outliers\n",
    "In addition, by checking the pdf file of financial benefits, I noticed that there were 2 clear outliers in the data, \"TOTAL\" and \"THE TRAVEL AGENCY IN THE PARK\". The first one seemed to be the sum total of all the other data points, while the second outlier was quite bizarre. Both these outliers and the datum with all NaN values, \"LOCKHART EUGENE E\", were removed from the dataset for all the analysis by applying __dict.pop(key, 0)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_nan(x):\n",
    "    return (x is np.nan or x != x)\n",
    "#create a dict that key is the feature name and values are a list of floats\n",
    "\n",
    "def dict_with_feature(dataset, sorting=False):\n",
    "    '''\n",
    "    define a dict with feature_key to better understand the distribution\n",
    "    key = feature name (salary, bonus, etc.)\n",
    "    value = list of values of each person\n",
    "    '''\n",
    "    dict_with_features = defaultdict(list)\n",
    "    for point, sub_dict in dataset.items():\n",
    "        for key, value in sub_dict.items():\n",
    "            #email address is a string, so pass to next when facing it\n",
    "            if key == 'email_address': continue\n",
    "            #create list to save values\n",
    "            if value == 'NaN':\n",
    "                if key == 'deferred_income':\n",
    "                    value = 10.\n",
    "                else: \n",
    "                    value = -10.\n",
    "                dict_with_features[key].append( float(value) )\n",
    "            else:\n",
    "                dict_with_features[key].append( float(value) )\n",
    "    #sorting values\n",
    "    if sorting:\n",
    "        for key, value in dict_with_features.items():\n",
    "            dict_with_features[key] = sorted(value, key = lambda x : float('-inf') if is_nan(x) else x)\n",
    "            #sorting nan reference: \n",
    "            #https://stackoverflow.com/questions/4240050/python-sort-function-breaks-in-the-presence-of-nan\n",
    "    return dict_with_features\n",
    "    #data points = 146 or 143\n",
    "    #nan means 0.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonR between poi and  loan_advances  :  (0.22018315467784991, 0.0082318533277599328)\n",
      "PearsonR between poi and  restricted_stock_deferred  :  (-0.021548443730261428, 0.79837555950439509)\n",
      "PearsonR between poi and  deferred_income  :  (-0.27415038034631295, 0.00092200531522211116)\n",
      "PearsonR between poi and  expenses  :  (0.20356124128833136, 0.014749906830119808)\n",
      "PearsonR between poi and  deferral_payments  :  (-0.039880323013413189, 0.63628313644857992)\n",
      "PearsonR between poi and  total_payments  :  (0.24202053177951902, 0.003589319021334966)\n",
      "PearsonR between poi and  long_term_incentive  :  (0.25640554881990896, 0.0019941673619026596)\n",
      "PearsonR between poi and  salary  :  (0.33885132032769316, 3.4782882030548758e-05)\n",
      "PearsonR between poi and  to_messages  :  (0.10762314208525051, 0.2007528121636562)\n",
      "PearsonR between poi and  exercised_stock_options  :  (0.38685273723309593, 1.8182211820386215e-06)\n",
      "PearsonR between poi and  from_this_person_to_poi  :  (0.1349683643031559, 0.10801392105201223)\n",
      "PearsonR between poi and  total_stock_value  :  (0.38262353734838972, 2.4043089131893602e-06)\n",
      "PearsonR between poi and  poi  :  (1.0, 0.0)\n",
      "PearsonR between poi and  shared_receipt_with_poi  :  (0.23966097464495092, 0.0039401691216989681)\n",
      "PearsonR between poi and  other  :  (0.16983000295074532, 0.042580414923631717)\n",
      "PearsonR between poi and  from_poi_to_this_person  :  (0.1925980246707418, 0.021192156728044927)\n",
      "PearsonR between poi and  director_fees  :  (-0.12188888360393317, 0.14700290183173831)\n",
      "PearsonR between poi and  bonus  :  (0.35848605315772913, 1.1012789919115899e-05)\n",
      "PearsonR between poi and  restricted_stock  :  (0.24765264180635183, 0.0028627778155170297)\n",
      "PearsonR between poi and  from_messages  :  (-0.034186015022908939, 0.68523064093101405)\n"
     ]
    }
   ],
   "source": [
    "dict_with_features = dict_with_feature(my_dataset)\n",
    "from scipy.stats.stats import pearsonr\n",
    "for key in dict_with_features.keys():\n",
    "    print ('PearsonR between poi and ', key, \" : \", \n",
    "           pearsonr(dict_with_features['poi'], dict_with_features[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Correlation between POI label and others\n",
    "To better predict who is more likely to be a POI, first of all I computed the correlation between label \"poi\" and the others, which was listed below:\n",
    "\n",
    " | Label 1 |  Label 2 |  Pearson's r |      \n",
    " | --- | --- | --- |\n",
    " | poi | exercised_stock_options | 0.387 |\n",
    " | poi | total_payments | 0.242 |\n",
    " | poi | expenses | 0.204 |\n",
    " | poi | deferral_payments | -0.040 |\n",
    " | poi | to_messages | 0.108 |\n",
    " | poi | other | 0.170 |\n",
    " | poi | restricted_stock | 0.248 |\n",
    " | poi | bonus | 0.358 |\n",
    " | poi | total_stock_value | 0.383 |\n",
    " | poi | restricted_stock_deferred | -0.022 |\n",
    " | poi | loan_advances | 0.220 |\n",
    " | poi | shared_receipt_with_poi | 0.240 |\n",
    " | poi | from_this_person_to_poi | 0.135 |\n",
    " | poi | long_term_incentive | 0.256 |\n",
    " | poi | from_messages | -0.034 |\n",
    " | poi | from_poi_to_this_person | 0.193 |\n",
    " | poi | deferred_income | -0.274 |\n",
    " | poi | salary | 0.339 |\n",
    " | poi | director_fees | -0.122 |\n",
    "\n",
    "According to the table, I noticed that there were no any strong relationships between the label \"poi\" and the others. Since I could not simply classify which labels had more impacts on making a person become a POI, I would like to add more computational labels and apply PCA, which stands for principal components analysis, to pick up the most related labels in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Adding new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##New Features\n",
    "From the initial dataset, Some new features were added, you can find more details in the table below:\n",
    "\n",
    "\n",
    " Feature        |  Description             \n",
    " :--- | --- \n",
    " Ratio of messages received from POI       | messages received from POI divided by total received messages\n",
    " Ratio of messages sent to POI    | messages sent to POI divided by total sent messages\n",
    " Comparison to Average (squared)      | features (financial and non-financial) divided by the average amount of the dataset          \n",
    " Comparison to Median (squared) | features (financial and non-financial) divided by the median amount (if not zero) of the dataset\n",
    "\n",
    "The reason behind the new features of message ratio created was that I expected that POI contacted with each other relatively more often than non-POI and the relationship might be non-linear. To enlarge the variance, I would like to squaring all the new features as well. I also expected that the financial gains of POI are more than the average and median, that was why I compared each feature with the average and median and squared it to get bigger variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loan_advances': 586878.3216783217, 'from_this_person_to_poi': 20.81118881118881, 'bonus': 680720.2727272727, 'expenses': 35619.293706293705, 'deferral_payments': 223635.2867132867, 'total_payments': 2272321.188811189, 'long_term_incentive': 339308.7272727273, 'from_poi_to_this_person': 35.04195804195804, 'salary': 186739.43356643355, 'restricted_stock': 874607.5944055944, 'to_messages': 1243.2307692307693, 'exercised_stock_options': 2090315.13986014, 'restricted_stock_deferred': 73922.5034965035, 'poi': 0.1258741258741259, 'shared_receipt_with_poi': 703.5384615384615, 'other': 296803.05594405596, 'deferred_income': -195031.05594405593, 'total_stock_value': 2930132.5034965035, 'director_fees': 10041.23076923077, 'from_messages': 362.13986013986016} {'loan_advances': -10.0, 'from_this_person_to_poi': 0.0, 'bonus': 300000.0, 'expenses': 21530.0, 'deferral_payments': -10.0, 'total_payments': 966522.0, 'long_term_incentive': -10.0, 'from_poi_to_this_person': 4.0, 'salary': 210692.0, 'restricted_stock': 360528.0, 'to_messages': 383.0, 'exercised_stock_options': 608750.0, 'restricted_stock_deferred': -10.0, 'poi': 0.0, 'shared_receipt_with_poi': 114.0, 'other': 947.0, 'deferred_income': 10.0, 'total_stock_value': 976037.0, 'director_fees': -10.0, 'from_messages': 18.0}\n"
     ]
    }
   ],
   "source": [
    "#Create new features about ratio of each feature to the mean and median of the feature\n",
    "mean_dict, median_dict = dict(), dict()\n",
    "#Create a dict to know each mean of feature\n",
    "for key, value in dict_with_features.items():\n",
    "    mean_dict[key] = sum(value)/len(value)\n",
    "    median_dict[key] = sorted(value)[int(len(value)/2)]\n",
    "print(mean_dict, median_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create feature list\n",
    "for point in my_dataset.keys():\n",
    "    for key in features_list:\n",
    "        try: mean_dict[key]\n",
    "        except: continue\n",
    "        if key != 'poi' and mean_dict[key] != 0:\n",
    "            my_dataset[point]['%s_mean_ratio' % key] = my_dataset[point][key] / mean_dict[key]\n",
    "        if key != 'poi' and median_dict[key] != 0:\n",
    "            my_dataset[point]['%s_median_ratio' % key] = my_dataset[point][key] / median_dict[key]\n",
    "#check\n",
    "#print(my_dataset['KISHKILL JOSEPH G'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAELCAYAAADdriHjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1112c36d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 71\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Creating new features with messages\n",
    "for sub_dict in my_dataset.values():\n",
    "    #Create ratio of messages received from poi to total received messages\n",
    "    if sub_dict['to_messages'] > 0. or sub_dict['to_messages'] < 0.:\n",
    "        sub_dict['from_poi_message_ratio'] = \\\n",
    "        (sub_dict['from_poi_to_this_person']/sub_dict['to_messages']) **2\n",
    "    else:\n",
    "        sub_dict['from_poi_message_ratio'] = 0.\n",
    "    #Create ratio of messages sent to poi to total messages sent\n",
    "    if sub_dict['from_messages'] > 0. or sub_dict['from_messages'] < 0.:\n",
    "        sub_dict['to_poi_message_ratio'] = \\\n",
    "        (sub_dict['from_this_person_to_poi']/sub_dict['from_messages']) **2\n",
    "    else:\n",
    "        sub_dict['to_poi_message_ratio'] = 0.\n",
    "\n",
    "    \n",
    "#Define a function to run the plotting and set threshold\n",
    "def plotting_function(dictionary, value1, value2, threshold1, threshold2, threshold_option = False):\n",
    "    counter_r, counter_b = 0, 0\n",
    "    for sub_dict in dictionary.values():\n",
    "        if sub_dict['poi'] > 0.:\n",
    "            plt.scatter(sub_dict[value1], sub_dict[value2], color = 'r')\n",
    "            if threshold_option:\n",
    "                if float(sub_dict[value1]) <= threshold1: print(value1, 'exception: ', sub_dict[value1])\n",
    "                elif float(sub_dict[value2]) <= threshold2: print(value2, 'exception: ', sub_dict[value2])\n",
    "                else: counter_r += 1\n",
    "        else:\n",
    "            if threshold_option:\n",
    "                if float(sub_dict[value1]) <= threshold1: continue\n",
    "                elif float(sub_dict[value2]) <= threshold2: continue\n",
    "            plt.scatter(sub_dict[value1], sub_dict[value2], color = 'b')\n",
    "            counter_b += 1\n",
    "    plt.xlabel(value1)\n",
    "    plt.ylabel(value2)\n",
    "    plt.savefig('poi_messages')\n",
    "    plt.show()\n",
    "    print(counter_r, counter_b)\n",
    "#show some figures\n",
    "plotting_function(my_dataset, 'from_poi_message_ratio', 'to_poi_message_ratio', 0.0004 , 0.03, True )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](poi_messages.png)\n",
    "After computing the ratio of messages received from poi to total received messages and messages sending to poi to total sent messages, I saw that the filter excluded 72 persons before excluded any POI wrongly. It seems like these two features will help me somehow when creating the machine learning classifier. Since I couldn't find any new features to describe data distribution better, next I would like to try some of machine learning algorithms and see which one performed better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Choosing machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Algorithms selection and tuning\n",
    "For the analysis of the data, a total of 6 classifiers was applied, which included:\n",
    "\n",
    "####Decision Tree Classifier\n",
    "####Gaussian Naive Bayes\n",
    "####Support Vector Classifier (SVC)\n",
    "####AdaBoost\n",
    "####Random Forrest Tree Classifier\n",
    "####K Nearest Neighbor\n",
    "\n",
    "The object of the algorithm was to classify and find out which people are more likely to be a POI. There were clearly 2 categories I was looking to label the data.\n",
    "\n",
    "When applying algorithms, If I did not change anything in the algorithm, it would apply all default parameters. But the default values might not always be the optimal, even doesn't work well for the learning algorithm. Thats's why I might need to \"tune the algorithm\". According to the Andrew Ng's MOOC \"Machine Learning\", there might be overfitting or underfitting when applying the algorithm. For example, the dataset had up to 58 features after some new features were added. If I didn't apply some feature selection methods like SelectKBest or decomposition methods like PCA, the algorithm would take all the features into calculation and have a great chance to become overfitting, because the calculation matrix would be up to 58 dimensions or even more if degree of the features was more than one. Also, there are many other inner parameters in each algorithm such as degree in SVC, which controls the degree of the optimal polynomial function it creates. When it is set very high, the algorithm would take a lot of time computing and more likely to become overfitting, but if it is set low like one or even less, the algorithm would compute much faster but more likely to become underfitting, which means it doesn't even fit the training set. When the algorithm is overfitting, it would be very specific to the training set but return poor accuracy with the test set. That's why I needed to try different parameters to find out the most fitting ones. For example, by changing the parameters in PCA, I might find some perform better than default setting and others. To see more details: https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning) \n",
    "\n",
    "First, to tune the algorithm, I applied PCA to decompose features and dimentions, and MaxAbsScaler to scale and normalize the features. Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components (or sometimes, principal modes of variation). The number of principal components is less than or equal to the smaller of the number of original variables or the number of observations. This transformation is defined in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components. I did not think the outcome would be the best when I put most features into the algorithms, either only few ones. Also for avoiding overfitting and underfitting, I would like to try PCA components, which meant to group the similar features, between 2 and 10 since there were 58 features in total in the dataset. MaxAbsScaler transforms a dataset of Vector rows, rescaling each feature to range [-1, 1] by dividing through the maximum absolute value in each feature. It does not shift/center the data, and thus does not destroy any sparsity. MaxAbsScaler computes summary statistics on a data set and produces a MaxAbsScalerModel. The model can then transform each feature individually to range [-1, 1].\n",
    "\n",
    "Also, when conducting machine learning algorithms, validation process must be necessary. A testing set would be needed to validate how the algorithm worked after training and it shall be independent of the training set. In a small or skewed dataset like this one, multiple times of validation process might avoid the algorithm to be biased and improve outcome reliability. To build a validation process, I would like to import the module StratifiedShuffleSplit from sklearn. It would return stratified randomized folds which depends on how many times you want to validate, and the training and testing data allocation would be based on appointed data spliting percentage. Since the Anron dataset was pretty small (only 143 persons) and very skewed POI distribution, I would like to set the cross-validation process to be repeated 1000 time and the tested size to be 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureFormat(dictionary, features, sort_keys = True):\n",
    "    '''definitely not a necessary function\n",
    "        just for the checking function in the tester.py'''\n",
    "    return_list = []\n",
    "    if sort_keys:\n",
    "        keys = sorted(dictionary.keys())\n",
    "    else:\n",
    "        keys = dictionary.keys()\n",
    "    for key in keys:\n",
    "        tmp_list = []\n",
    "        for feature in features:\n",
    "            value = dictionary[key][feature]\n",
    "            tmp_list.append( float(value) )\n",
    "        if features[0] == 'poi':\n",
    "            test_list = tmp_list[1:]\n",
    "        else:\n",
    "            test_list = tmp_list\n",
    "        return_list.append( tmp_list )\n",
    "    return np.array(return_list)\n",
    "\n",
    "def targetFeatureSplit( data ):\n",
    "    '''definitely not a necessary function\n",
    "    just for the checking function in the tester.py'''\n",
    "    target = []\n",
    "    features = []\n",
    "    for item in data:\n",
    "        target.append( item[0] )\n",
    "        features.append( item[1:] )\n",
    "\n",
    "    return target, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KunWuYao/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "    \n",
    "data = featureFormat(my_dataset, reset_feature_list(my_dataset), sort_keys = True)\n",
    "#features order is organized by names of people \n",
    "\n",
    "# one data point is consist of zeros n NaN values\n",
    "labels, features = targetFeatureSplit( data )\n",
    "\n",
    "#normalize the features before running!\n",
    "# http://scikit-learn.org/stable/modules/preprocessing.html\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "min_max_scaler = MaxAbsScaler()\n",
    "features_normalized = min_max_scaler.fit_transform(features)\n",
    "\n",
    "#naive_bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#svm\n",
    "from sklearn.svm import SVC\n",
    "#random forest, adaboost\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "#decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#K nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def algorithm_tester(algorithm, test_times, n_range):\n",
    "    '''for every PCA n_component in each algorithm\n",
    "    run pipe.fit 100 times to see how precision and recall scores it is\n",
    "    test_times can be 100 or 1000\n",
    "    n_range shall be a list including 2 integers'''\n",
    "    algorithm_tester = []\n",
    "    for n in range(n_range[0], n_range[1]):\n",
    "        clf = Pipeline([('reduce_dim', PCA(n_components = n)), ('clf', algorithm)])\n",
    "        sss = StratifiedShuffleSplit(test_times, test_size = 0.1, random_state = 42)\n",
    "        true_negatives = 0\n",
    "        false_negatives = 0\n",
    "        true_positives = 0\n",
    "        false_positives = 0\n",
    "        for train_idx, test_idx in sss.split(features_normalized, labels):\n",
    "        #reference: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html\n",
    "            features_train = []\n",
    "            features_test  = []\n",
    "            labels_train   = []\n",
    "            labels_test    = []    \n",
    "            for ii in train_idx:\n",
    "                features_train.append( features_normalized[ii] )\n",
    "                labels_train.append( labels[ii] )\n",
    "            for jj in test_idx:\n",
    "                features_test.append( features_normalized[jj] )\n",
    "                labels_test.append( labels[jj] )\n",
    "            ### fit the classifier using training set, and test on test set\n",
    "            clf.fit(features_train, labels_train)\n",
    "            predictions = clf.predict(features_test)\n",
    "            for prediction, truth in zip(predictions, labels_test):\n",
    "                if prediction == 0 and truth == 0:\n",
    "                    true_negatives += 1\n",
    "                elif prediction == 0 and truth == 1:\n",
    "                    false_negatives += 1\n",
    "                elif prediction == 1 and truth == 0:\n",
    "                    false_positives += 1\n",
    "                elif prediction == 1 and truth == 1:\n",
    "                    true_positives += 1\n",
    "                else:\n",
    "                    print (\"Warning: Found a predicted label not == 0 or 1.\")\n",
    "                    print (\"All predictions should take value 0 or 1.\")\n",
    "                    print (\"Evaluating performance for processed predictions:\")\n",
    "                    break\n",
    "        try:\n",
    "            total_predictions = true_negatives + false_negatives + \\\n",
    "                                false_positives + true_positives\n",
    "            precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "            recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "            accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "\n",
    "        except: continue\n",
    "        if precision >= 0.3 and recall >= 0.3:\n",
    "            tmp_list = [recall, precision, accuracy] # [avg_recall, avg_precision, avg_accuracy, n_component]\n",
    "            tmp_list.append(n)\n",
    "            algorithm_tester.append(tmp_list)\n",
    "    return algorithm_tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algorithms_comparison = dict()\n",
    "algorithms_comparison['Naive Bayes'] = algorithm_tester(\n",
    "    GaussianNB(), 100, [2, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithms_comparison['SVM'] = algorithm_tester(\n",
    "    SVC(), 100, [2, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithms_comparison['Decision Tree'] = algorithm_tester(\n",
    "    DecisionTreeClassifier(), 100, [2, 11] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithms_comparison['Random Forest'] = algorithm_tester(\n",
    "    RandomForestClassifier(), 100,[2, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algorithms_comparison['AdaBoost'] = algorithm_tester(\n",
    "    AdaBoostClassifier(), 100, [2, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithms_comparison['K Nearest Neighbors'] = algorithm_tester(\n",
    "    KNeighborsClassifier(), 100, [2, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Naive Bayes': [[0.345, 0.46938775510204084, 0.8606666666666667, 8], [0.385, 0.4935897435897436, 0.8653333333333333, 9], [0.385, 0.46107784431137727, 0.858, 10]], 'AdaBoost': [], 'Decision Tree': [], 'K Nearest Neighbors': [], 'SVM': [], 'Random Forest': []}\n"
     ]
    }
   ],
   "source": [
    "print(algorithms_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Validation and Performance\n",
    "\n",
    "By running the machine learning codes, I noticed that every algorithm return high accuracy, but does that mean the prediction is good? Or that just results from the low ratio of persons of interest to all people in the dataset? Especially the POI distribution was pretty skewed with only 18 out of the 143 persons. How would the accuracy be if I predicted all persons to be a non-POI? 87.41%, which would be pretty high but nothing valuable to the predicting algorithm. To better evaluate how the outcomes were return by the algorithms I applied, I would like to compute the recall and precision scores instead of accuracy. You might check wiki for more details: [Wiki Precision and Recall][0] In this case, precision score measured how many POI the algorithms predicted were truely POI, and recall score measured how many POI the algorithms failed to detect, which meant the algorithm predicted he/she to be a non-POI. In other words, in a skewed dataset with very few true values, to predict a negative value is much easier than to predict a true value. As mentioned earlier, the accuracy was still pretty high even I did not predict any person to be POI. If I measure the accuracy with precision and recall score instead, the all non-POI prediction would get poor score because it did not predict anybody to be a POI. Concretely, recall and precision scores might better evaluate whether the algorithm worked well on predicting positive values in a skewed dataset.\n",
    "After computing recall and precision scores, I found that some algorithms get really bad recall and precision scores. In addition, after testing multiple times, I found that only Naive Bayes returned  recall and precision scores both higher than 0.3. Additionally, there were many different n_component choices in PCA process when running Naive Bayes as the chosen algorithm. Here are the algorithms and PCA choices with both recall and precision scores higher than 0.3:\n",
    "\n",
    " | ML Method |  PCA n_components |  Recall Score |  Precision Score |      \n",
    " | --- | --- | --- | --- |\n",
    " | Naive Bayes GaussianNB | 2 | 0.330 | 0.584 | \n",
    " | Naive Bayes GaussianNB | 3 | 0.330 | 0.555 | \n",
    " | Naive Bayes GaussianNB | 4 | 0.305 | 0.513 | \n",
    " | Naive Bayes GaussianNB | 7 | 0.330 | 0.443 | \n",
    " | Naive Bayes GaussianNB | 8 | 0.390 | 0.446 | \n",
    " | Naive Bayes GaussianNB | 9 | 0.330 | 0.410 | \n",
    " | Naive Bayes GaussianNB | 10 | 0.305 | 0.415 |\n",
    " | Decision Tree | 3 | 0.335 | 0.310 |\n",
    " | Decision Tree | 5 | 0.310 | 0.302 |\n",
    " |Results WILL vary. There is some randomness in the data splitting |  \n",
    "\n",
    "From this table we might find that applying algorithm Naive Bayes GaussianNB with 2 to 4 and 7 to 9 PCA n_components would returned the best outcome.\n",
    "\n",
    "[0]: https://en.wikipedia.org/wiki/Precision_and_recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.34, 0.4336734693877551, 0.8528, 9], [0.3435, 0.413855421686747, 0.8476, 10]]\n"
     ]
    }
   ],
   "source": [
    "best_outcome = algorithm_tester(GaussianNB(), 1000, [2, 11])\n",
    "print(best_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate the performance of each algorithm, **recall** and **precision** scores were calculated for each one. The scores of the best algorithm were listed below:\n",
    "\n",
    " |Algorithm        |  PCA n_component | Features included |  Recall | Precision |           \n",
    " |:--- | --- | --- | --- | \n",
    " |Naive Bayes GaussianNB | 9 | 58 | 0.340 | 0.434 | \n",
    " |Results WILL vary. There is some randomness in the data splitting \n",
    " \n",
    "The best classifier was actually *Naive Bayes GaussianNB* using PCA beforehand. This was achieved by using sklearn Pipline. The GaussianNB achieved a consistent score above 0.30 for both precision and recall. The final parameters applied are detailed below:\n",
    "\n",
    "##### Pipeline([('reduce_dim', PCA(n_components = 9)), ('clf', GaussianNB())])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Discussion and Conclusions\n",
    "\n",
    "###New features impact\n",
    "\n",
    "When conducting this project, I added a lot of new features. I'd like to compare what each algorithm returned with no any new features added or even no penalty for the NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try if we don't add any new features\n",
    "with open(\"final_project_dataset.pkl\", \"rb\") as data_file:\n",
    "    my_dataset_o = pickle.load(data_file)\n",
    "my_dataset_o = remove_nan(my_dataset_o, 0., remove_outlier = True)\n",
    "features_list = reset_feature_list(my_dataset_o)\n",
    "data_o = featureFormat(my_dataset_o, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit( data_o ) \n",
    "features_normalized = min_max_scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithms_comparison_o = dict()\n",
    "algorithms_comparison_o['Naive Bayes'] = algorithm_tester(GaussianNB(),100, [2, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithms_comparison_o['SVM'] = algorithm_tester(SVC(),100,[2, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithms_comparison_o['Decision Tree'] = algorithm_tester(DecisionTreeClassifier(),100,[2, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithms_comparison_o['Random Forest'] = algorithm_tester(RandomForestClassifier(),100, [2, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithms_comparison_o['AdaBoost'] = algorithm_tester(AdaBoostClassifier(),100, [2, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithms_comparison_o['K Nearest Neighbors'] = algorithm_tester(KNeighborsClassifier(),100, [2, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K Nearest Neighbors': [], 'AdaBoost': [], 'Decision Tree': [], 'Naive Bayes': [[0.31, 0.34065934065934067, 0.828, 5], [0.33, 0.3707865168539326, 0.836, 6], [0.375, 0.38860103626943004, 0.838, 7], [0.405, 0.391304347826087, 0.8366666666666667, 8], [0.405, 0.38388625592417064, 0.834, 9], [0.41, 0.39805825242718446, 0.8386666666666667, 10]], 'Random Forest': [], 'SVM': []}\n"
     ]
    }
   ],
   "source": [
    "print(algorithms_comparison_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.319, 0.33756613756613757, 0.8257333333333333, 7], [0.365, 0.3573176700930005, 0.8278, 8], [0.357, 0.35172413793103446, 0.8265333333333333, 9]]\n"
     ]
    }
   ],
   "source": [
    "best_outcome_o = (algorithm_tester(GaussianNB(),1000, [2, 10]))\n",
    "print(best_outcome_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " |Algorithm        |  PCA n_component | Features included |  Recall | Precision |           \n",
    " |:--- | --- | --- | --- | \n",
    " |Naive Bayes GaussianNB | 8 | 19 | 0.365 | 0.357 | \n",
    " |Results WILL vary. There is some randomness in the data splitting \n",
    " \n",
    "After running to get the consequences, I found that after lots of new features were added, the best score was only a little higher (pushed precision score from 0.357 up to 0.434 but made recall score drop to 0.340), and that made me think maybe PCA was not the best method to find out how many and which features I shall pick up. Actually, PCA is very usful when conducting face recognizing or database with a tremendous amount of features but not very helpful with small database like this one.\n",
    "To find out whether other algorithms can get higher scores, I would like to remove PCA and try another feature selection tool: SelectKBest. SelectKBest would search in the features list and return the features with highest importance. It can be combined with GridSearchCV to find out how many features might return the best outcome. That is really important because in a dataset with hundreds of features or more, there might be a lot of features which are unimportant/insignificant to the label we want to predict. Putting all features into the algorithm would not only slow down the computation process but also influence the algorithm to make improper predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "#turn warning messages off!\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)  result table:  {'select__k': 16}\n",
      "Features index list:  [ True  True  True False False False  True  True  True False False False\n",
      "  True  True  True False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False  True  True  True False False False\n",
      " False False False False False False False  True  True  True]\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)  result table:  {'select__k': 7}\n",
      "Features index list:  [False  True False False False False False False False False False False\n",
      "  True  True  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True  True]\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')  result table:  {'select__k': 9}\n",
      "Features index list:  [ True  True  True False False False False False False False False False\n",
      "  True  True  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True  True]\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)  result table:  {'select__k': 9}\n",
      "Features index list:  [ True  True  True False False False False False False False False False\n",
      "  True  True  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True  True]\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)  result table:  {'select__k': 50}\n",
      "Features index list:  [ True  True  True False  True False  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False False False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False False False  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')  result table:  {'select__k': 8}\n",
      "Features index list:  [False  True  True False False False False False False False False False\n",
      "  True  True  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "#Try to find out some usful features\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import f_classif, f_regression\n",
    "### StratifiedShuffleSplits for 1000 internal cross-validation splits\n",
    "### within the grid-search.\n",
    "labels, features = targetFeatureSplit( data )\n",
    "features_normalized = min_max_scaler.fit_transform(features)\n",
    "sss = StratifiedShuffleSplit(n_splits=1000, test_size = 0.1, random_state = 42)\n",
    "dt_clf_best_params = []\n",
    "param_grid = {#'pca__n_components': [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'select__k': [2, 3, 4, 5, 6, 7, 8, 9, \n",
    "                          10, 12, 14, 16, 18, 20, 25, 30, 40, 50]\n",
    "           # 'select__score_func': [f_classif, f_regression] #f_classif got better than f_regression\n",
    "             }\n",
    "clf_list = [GaussianNB(), SVC(), DecisionTreeClassifier(), RandomForestClassifier(),\n",
    "            AdaBoostClassifier(), KNeighborsClassifier()]\n",
    "\n",
    "for clf in clf_list:\n",
    "    # Pipeline object\n",
    "    pipe = Pipeline(steps=[('minabser', MaxAbsScaler()),\n",
    "                        ('select', SelectKBest()), \n",
    "                        #('pca', PCA()),\n",
    "                        ('model', clf)   \n",
    "                        ])\n",
    "    dt_search = GridSearchCV(pipe, param_grid=param_grid, cv=sss,\n",
    "                        scoring = 'f1')\n",
    "    #print(dt_search.get_params)\n",
    "    dt_search.fit(features, labels)\n",
    "    ### Score of best_estimator on the left out data\n",
    "    # Print the optimized parameters used in the model selected from grid search\n",
    "    print('%s' % clf, ' result table: ', dt_search.best_params_)\n",
    "    print('Features index list: ', dt_search.best_estimator_.named_steps['select'].get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def algorithm_tester_tuned(algorithm, tuning_params, test_times):\n",
    "    '''for every PCA n_component in each algorithm\n",
    "    run pipe.fit 100 times to see how precision and recall scores it is\n",
    "    test_times can be 100 or 1000\n",
    "    n_range shall be a list including 2 integers'''\n",
    "    algorithm_tester = []\n",
    "    clf = Pipeline([('minabser', MaxAbsScaler()),\n",
    "                    ('select', SelectKBest()), \n",
    "                    ('clf', algorithm) \n",
    "                       ])\n",
    "    sss = StratifiedShuffleSplit(test_times, test_size = 0.1, random_state = 42)\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in sss.split(features, labels):\n",
    "    #reference: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html\n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []    \n",
    "        for ii in train_idx:\n",
    "            features_train.append( features_normalized[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features_normalized[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.set_params(**tuning_params).fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print (\"Warning: Found a predicted label not == 0 or 1.\")\n",
    "                print (\"All predictions should take value 0 or 1.\")\n",
    "                print (\"Evaluating performance for processed predictions:\")\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + \\\n",
    "                            false_positives + true_positives\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "\n",
    "    except: return ValueError\n",
    "    tmp_list = [recall, precision, accuracy] # [avg_recall, avg_precision, avg_accuracy, n_component]\n",
    "    algorithm_tester.append(tmp_list)\n",
    "    return algorithm_tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVC_best_param = {'select__k': 7}\n",
    "algorithms_comparison['SVC'] = algorithm_tester_tuned(\n",
    "    SVC(), SVC_best_param, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_best_param = {'select__k': 16}\n",
    "algorithms_comparison['Naive Bayes'] = algorithm_tester_tuned(\n",
    "    GaussianNB(), NB_best_param, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DT_best_param = {'select__k': 9}\n",
    "algorithms_comparison['Decision Tree'] = algorithm_tester_tuned(\n",
    "    DecisionTreeClassifier(), DT_best_param, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF_best_param = {'select__k': 9}\n",
    "algorithms_comparison['Random Forest'] = algorithm_tester_tuned(\n",
    "    RandomForestClassifier(), RF_best_param, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adaboost_best_param = {'select__k': 50}\n",
    "algorithms_comparison['Adaboost'] = algorithm_tester_tuned(\n",
    "    AdaBoostClassifier(), adaboost_best_param, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_best_param = {'select__k': 8}\n",
    "algorithms_comparison['K Nearest Neighbors'] = algorithm_tester_tuned(\n",
    "    KNeighborsClassifier(), KNN_best_param, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K Nearest Neighbors': [[0.237, 0.7011834319526628, 0.8848]], 'AdaBoost': [], 'Decision Tree': [[0.357, 0.3216216216216216, 0.8138666666666666]], 'Adaboost': [[0.3385, 0.41815935762816553, 0.849]], 'Naive Bayes': [[0.374, 0.38516992790937177, 0.8369333333333333]], 'Random Forest': [[0.2635, 0.4395329441201001, 0.857]], 'SVM': [], 'SVC': [[0.0385, 0.9625, 0.8716]]}\n"
     ]
    }
   ],
   "source": [
    "print(algorithms_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Features Selection\n",
    "####SelectKBest\n",
    "With each algorithm tuned with its best k features assessed by f1 score, the scores are listed below:\n",
    " \n",
    " |Algorithm        |  Best k Features Number |  Recall | Precision |          \n",
    " |:--- | --- | --- | --- | \n",
    " |Random Forest | 9 |  0.269 | 0.445 |\n",
    " |Decision Tree | 9 | 0.3575 | 0.322 |\n",
    " |Adaboost | 50 | 0.339 | 0.418 |\n",
    " |Naive Bayes | 16 | 0.374 | 0.385 |\n",
    " |KNN | 8 | 0.237 | 0.701 |\n",
    " |SVC | 7 | 0.039 | 0.963 |\n",
    "\n",
    "In this case, each algorithm except for Naive Bayes got a huge improvement, and DecisionTreeClassifier and AdaBoostClassifier pushed both recall and precision scores higher than 0.3! Although KNeighborsClassifier and SVC achieved pretty high precision scores, but they had bad recall scores. To try to get better scores, next I would like to try finding out the best parameters set for KNeighborsClassifier, making its scores higher than 0.3 as well. KNN has some inner parameters, and the parameters I would like to search for the best fit are listed below:\n",
    "\n",
    "|Algorithm        |  Parameter Name |  Definition |      \n",
    "|:--- | --- | --- |\n",
    "|K Nearest Neighbors | n_neighbors | Number of neighbors to use by default for kneighbors queries. How many groups in the algorithm|\n",
    "|K Nearest Neighbors | weights | weight function used in prediction. Possible values: ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.  ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.   [callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights. |\n",
    "|K Nearest Neighbors | leaf_size| Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')  result table:  {'model__weights': 'distance', 'select__k': 8, 'model__leaf_size': 10, 'model__n_neighbors': 3}\n",
      "Features index list:  [False  True  True False False False False False False False False False\n",
      "  True  True  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=100, test_size = 0.1, random_state = 42)\n",
    "param_grid = {'select__k': [2, 3, 4, 5, 6, 7, 8, 9, \n",
    "                          10, 12, 14, 16, 18, 20],\n",
    "             'model__n_neighbors': [3, 5, 7, 9, 11],\n",
    "             'model__weights': ['uniform', 'distance'], #already tried rbf and sigmoid and worse than poly\n",
    "             'model__leaf_size': [10, 20, 30, 40]\n",
    "             } #push up dimention did not help at all\n",
    "##Search for best_params for KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "## Pipeline object\n",
    "pipe = Pipeline(steps=[('minabser', MaxAbsScaler()),\n",
    "                    ('select', SelectKBest()), \n",
    "                    ('model', clf)   \n",
    "                    ])\n",
    "dt_search = GridSearchCV(pipe, param_grid=param_grid, cv=sss,\n",
    "                    scoring = 'f1')\n",
    "##print(dt_search.get_params)\n",
    "dt_search.fit(features, labels)\n",
    "### Score of best_estimator on the left out data\n",
    "## Print the optimized parameters used in the model selected from grid search\n",
    "print('%s' % clf, ' result table: ', dt_search.best_params_)\n",
    "print('Features index list: ', dt_search.best_estimator_.named_steps['select'].get_support())\n",
    "knn_bestkfeature = dt_search.best_estimator_.named_steps['select'].get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K Nearest Neighbors': [[0.3105, 0.476592478894858, 0.8626]], 'AdaBoost': [], 'Decision Tree': [[0.357, 0.3216216216216216, 0.8138666666666666]], 'Adaboost': [[0.3385, 0.41815935762816553, 0.849]], 'Naive Bayes': [[0.374, 0.38516992790937177, 0.8369333333333333]], 'Random Forest': [[0.2635, 0.4395329441201001, 0.857]], 'SVM': [], 'SVC': [[0.0385, 0.9625, 0.8716]]}\n"
     ]
    }
   ],
   "source": [
    "KNN_best_param = {'select__k': 8, 'clf__n_neighbors': 3, 'clf__leaf_size': 10,\n",
    "                 'clf__weights': 'distance'}\n",
    "algorithms_comparison['K Nearest Neighbors'] = algorithm_tester_tuned(\n",
    "    KNeighborsClassifier(), KNN_best_param, 1000)\n",
    "print(algorithms_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 58\n",
      "['bonus_mean_ratio', 'bonus_median_ratio', 'exercised_stock_options', 'exercised_stock_options_mean_ratio', 'exercised_stock_options_median_ratio', 'total_stock_value', 'total_stock_value_mean_ratio', 'total_stock_value_median_ratio']\n"
     ]
    }
   ],
   "source": [
    "features_list = reset_feature_list(my_dataset)\n",
    "print(len(features_list[1:]), len(knn_bestkfeature))\n",
    "finalized_features_list = []\n",
    "for boolean, feature in zip(knn_bestkfeature, features_list[1:]):\n",
    "    if boolean == True and feature not in finalized_features_list:\n",
    "        finalized_features_list.append(feature)\n",
    "print(finalized_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying different parameters in KNN algorithm, the recall and precision scores were pushed up to 0.3105 and 0.4766 separately, with the following parameter setting:\n",
    " \n",
    " |  Function |  Parameter Key    |  Parameter Value  |  \n",
    " |:--- | --- | --- |\n",
    " |SelectKBest | k | 8 |\n",
    " |KNeighborsClassifier | n_neighbors | 3|\n",
    " |KNeighborsClassifier | leaf_size | 10|\n",
    " |KNeighborsClassifier | weights | distance |\n",
    " \n",
    " And the selected features were:\n",
    " ['bonus_mean_ratio', 'bonus_median_ratio', 'exercised_stock_options', 'exercised_stock_options_mean_ratio', 'exercised_stock_options_median_ratio', 'total_stock_value', 'total_stock_value_mean_ratio', 'total_stock_value_median_ratio']\n",
    " \n",
    "Compared the outcome with Naive Bayes tuned with PCA, KNN with tuned parameters and SelectKBest returns better scores, so I would like to choose KNN as my final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The results should not be taken too seriously and more advanced models should be used. Possibilities for future research could be to include more complex pipelines for the data, try different feature selecting tools and learning parameters, or even Neural Networks. This was just a starting point analysis for classifying Enron employees, and I would like to try and learn more tools and algorithms to make the prediction better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##References\n",
    "\n",
    "[Udacity - Intro to Machine Learning course] [0]\n",
    "\n",
    "[Sklearn documentation] [1]\n",
    "\n",
    "[Feature selecting] [2]\n",
    "\n",
    "[0]: https://www.udacity.com/course/intro-to-machine-learning--ud120\n",
    "[1]: http://scikit-learn.org/stable/documentation.html \n",
    "[2]: http://machinelearningmastery.com/feature-selection-machine-learning-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (tester.py, line 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/Users/KunWuYao/Desktop/Python shortcut/Python Exercise ver3/Udacity/Data Analyst Nanodegree/Project5/tester.py\"\u001b[0;36m, line \u001b[0;32m57\u001b[0m\n\u001b[0;31m    print \"Warning: Found a predicted label not == 0 or 1.\"\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "from tester import dump_classifier_and_data, test_classifier\n",
    "clf = Pipeline([('minabser', MaxAbsScaler()),\n",
    "                    ('reduce_dim', SelectKBest(k = 8)), \n",
    "                 ('clf', KNeighborsClassifier(n_neighbors = 3, leaf_size = 10, \n",
    "                                              weights = 'distance'))])\n",
    "features_list = reset_feature_list(my_dataset)\n",
    "#test final output\n",
    "test_classifier(clf, my_dataset, features_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dump_classifier_and_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2da21b3e921c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Finally, output the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdump_classifier_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dump_classifier_and_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Finally, output the data\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
